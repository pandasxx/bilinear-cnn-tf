{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-C 预测\n",
    "\n",
    "### 1.加载CONV层参数，加载FC层参数\n",
    "\n",
    "### 2.运行模型预测Submit数据\n",
    "\n",
    "### 3.写入CSV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from data_preprocess import *\n",
    "from image_preprocess import *\n",
    "from bcnn_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_file = \"vgg16_weights.npz\"\n",
    "weights_file_last_layer = \"bcnn_last_weights.npz\"\n",
    "weights_file_conv = \"bcnn_conv_weights.npz\"\n",
    "\n",
    "image_size = 224\n",
    "n_classes = 12\n",
    "submit_size = 794\n",
    "submit_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3, 4, 5, 6, 7, 8]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "test = [0,1,2,3,4,5,6,7,8]\n",
    "print(test[:2])\n",
    "print(test[2:])\n",
    "print(test[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Data Augmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\XX\\Anaconda2\\envs\\gpu-env-tf\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of z (?, 262144)\n",
      "conv_layer [[[[ 4.79724169e-01 -1.77854285e-01  3.73495892e-02 ... -1.19056016e-01\n",
      "    -4.86118235e-02  3.06583364e-02]\n",
      "   [ 5.51010847e-01  1.77014191e-02  9.87275243e-02 ... -7.65096173e-02\n",
      "    -5.11239022e-02  3.40547599e-02]\n",
      "   [ 4.33386236e-01  1.11716330e-01  3.39476205e-02 ... -1.23892114e-01\n",
      "    -5.15401624e-02  2.80593429e-03]]\n",
      "\n",
      "  [[ 4.08727527e-01 -1.75623596e-01 -5.17894607e-03 ... -1.14073545e-01\n",
      "    -2.74549335e-01 -4.30106670e-02]\n",
      "   [ 4.40814644e-01  4.41833548e-02  5.12870811e-02 ... -9.06181559e-02\n",
      "    -2.96373188e-01 -7.38389939e-02]\n",
      "   [ 3.77239496e-01  1.56427950e-01  1.65483530e-03 ... -1.39607966e-01\n",
      "    -2.33262092e-01 -6.75706193e-02]]\n",
      "\n",
      "  [[-6.46550357e-02 -1.59813732e-01 -1.38237387e-01 ... -1.21087477e-01\n",
      "    -4.60065842e-01 -3.27527791e-01]\n",
      "   [-8.09265971e-02  3.83964740e-02 -1.01794742e-01 ... -8.62325355e-02\n",
      "    -5.05873263e-01 -3.87156606e-01]\n",
      "   [-5.80082461e-02  1.29876092e-01 -1.15684174e-01 ... -1.31812900e-01\n",
      "    -3.75346690e-01 -3.04792553e-01]]]\n",
      "\n",
      "\n",
      " [[[ 3.10511976e-01 -1.92836687e-01  1.66434437e-01 ... -9.05647501e-02\n",
      "     4.05646741e-01  3.88536543e-01]\n",
      "   [ 3.46441329e-01  2.78811380e-02  2.40706414e-01 ... -6.09953105e-02\n",
      "     4.37702477e-01  4.10418004e-01]\n",
      "   [ 2.78558969e-01  1.42607197e-01  1.61559463e-01 ... -1.05718940e-01\n",
      "     3.67508531e-01  3.35455507e-01]]\n",
      "\n",
      "  [[ 5.05742952e-02 -1.82902351e-01  1.51018351e-01 ... -5.52958855e-03\n",
      "     2.61269093e-01  4.20185059e-01]\n",
      "   [ 4.10676189e-02  6.26706406e-02  2.20273152e-01 ...  4.50072484e-03\n",
      "     2.69928604e-01  4.06899750e-01]\n",
      "   [ 4.22152802e-02  1.96487844e-01  1.56422794e-01 ... -4.31059003e-02\n",
      "     2.59451687e-01  3.67556989e-01]]\n",
      "\n",
      "  [[-4.02497858e-01 -1.79951131e-01 -1.10028073e-01 ... -1.17246330e-01\n",
      "    -3.12013447e-01 -2.36385465e-01]\n",
      "   [-4.53114212e-01  4.28013839e-02 -6.67407811e-02 ... -9.55144167e-02\n",
      "    -3.45826447e-01 -2.95777828e-01]\n",
      "   [-3.63777250e-01  1.55703723e-01 -8.99074748e-02 ... -1.37419298e-01\n",
      "    -2.69550532e-01 -2.43979350e-01]]]\n",
      "\n",
      "\n",
      " [[[-5.05856499e-02 -1.71153605e-01  1.54278390e-02 ... -1.41754076e-01\n",
      "     3.07684243e-01  8.37005228e-02]\n",
      "   [-5.81698939e-02  2.84500569e-02  7.58788064e-02 ... -9.69675779e-02\n",
      "     3.39955002e-01  9.54201147e-02]\n",
      "   [-5.38961329e-02  1.23590492e-01  1.28548015e-02 ... -1.33165836e-01\n",
      "     2.42733493e-01  4.05835882e-02]]\n",
      "\n",
      "  [[-2.84648955e-01 -1.71909750e-01 -8.19956604e-03 ... -1.01602919e-01\n",
      "     2.80632854e-01  9.05621424e-02]\n",
      "   [-3.30541939e-01  5.15080616e-02  4.85808328e-02 ... -7.49806166e-02\n",
      "     2.96084285e-01  7.14421496e-02]\n",
      "   [-2.58964509e-01  1.65774986e-01 -2.21455521e-05 ... -1.14234067e-01\n",
      "     2.46788353e-01  4.86697219e-02]]\n",
      "\n",
      "  [[-4.17370498e-01 -1.62516162e-01 -1.49362221e-01 ... -1.48707747e-01\n",
      "    -1.41250774e-01 -2.73369759e-01]\n",
      "   [-4.84682232e-01  3.88077199e-02 -1.12133473e-01 ... -1.10646546e-01\n",
      "    -1.66844785e-01 -3.25387388e-01]\n",
      "   [-3.46785456e-01  1.32746696e-01 -1.25367314e-01 ... -1.44915417e-01\n",
      "    -1.37746736e-01 -2.69394130e-01]]]]\n",
      "last_layer [[ 9.5096119e-02  7.2866559e-02 -3.7099238e-02 ... -3.4209192e-02\n",
      "  -8.8295311e-02  5.0671201e-02]\n",
      " [ 1.3885685e-03 -1.4520059e-03 -3.7153980e-03 ...  4.9796095e-03\n",
      "  -6.6730520e-04 -8.2662809e-05]\n",
      " [ 5.5598512e-02  4.8294347e-02 -4.3314923e-02 ... -5.8819026e-02\n",
      "  -2.5620159e-02  5.1873967e-02]\n",
      " ...\n",
      " [-2.9140688e-04  7.9463888e-03 -5.1188129e-03 ... -1.3585651e-03\n",
      "  -7.6159241e-04 -4.8623886e-03]\n",
      " [ 8.8658873e-03  3.4448884e-05 -3.1030427e-03 ... -6.2429928e-03\n",
      "  -6.1974237e-03 -2.8256401e-03]\n",
      " [ 7.6429680e-02  5.7216074e-02  5.7425611e-02 ... -5.1335607e-02\n",
      "   4.4645220e-02 -7.5375348e-02]]\n",
      "Adding weights to conv1_1/W:0\n",
      "Adding weights to conv1_1/b:0\n",
      "Adding weights to conv1_2/W:0\n",
      "Adding weights to conv1_2/b:0\n",
      "Adding weights to conv2_1/W:0\n",
      "Adding weights to conv2_1/b:0\n",
      "Adding weights to conv2_2/W:0\n",
      "Adding weights to conv2_2/b:0\n",
      "Adding weights to conv3_1/W:0\n",
      "Adding weights to conv3_1/b:0\n",
      "Adding weights to conv3_2/W:0\n",
      "Adding weights to conv3_2/b:0\n",
      "Adding weights to conv3_3/W:0\n",
      "Adding weights to conv3_3/b:0\n",
      "Adding weights to conv4_1/W:0\n",
      "Adding weights to conv4_1/b:0\n",
      "Adding weights to conv4_2/W:0\n",
      "Adding weights to conv4_2/b:0\n",
      "Adding weights to conv4_3/W:0\n",
      "Adding weights to conv4_3/b:0\n",
      "Adding weights to conv5_1/W:0\n",
      "Adding weights to conv5_1/b:0\n",
      "Adding weights to conv5_2/W:0\n",
      "Adding weights to conv5_2/b:0\n",
      "Adding weights to conv5_3/W:0\n",
      "Adding weights to conv5_3/b:0\n",
      "Adding weights to fc-new/W:0\n",
      "Adding weights to fc-new/b:0\n",
      "Trainable variables <tf.Variable 'conv1_1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv1_1/b:0' shape=(64,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv1_2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv1_2/b:0' shape=(64,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv2_1/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv2_1/b:0' shape=(128,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv2_2/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv2_2/b:0' shape=(128,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_1/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_1/b:0' shape=(256,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_2/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_2/b:0' shape=(256,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_3/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv3_3/b:0' shape=(256,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_1/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_1/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_2/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv4_3/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_1/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_1/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_2/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_2/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_3/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'conv5_3/b:0' shape=(512,) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'fc-new/W:0' shape=(262144, 12) dtype=float32_ref>\n",
      "Trainable variables <tf.Variable 'fc-new/b:0' shape=(12,) dtype=float32_ref>\n",
      "Starting predicting\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 0\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 1\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 2\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 3\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 4\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 5\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 6\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 7\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 8\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 9\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 10\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 11\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 12\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 13\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 14\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 15\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 16\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 17\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 18\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 19\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 20\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 21\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 22\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 23\n",
      "1\n",
      "2\n",
      "3\n",
      "completed 24\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "# build input\n",
    "imgs = tf.placeholder(tf.float32, shape = [None, image_size, image_size, 3], name = \"input_x\")\n",
    "keep_prob = tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "\n",
    "# build cal graph\n",
    "bilinear_cnn = vgg_bilinear_model(imgs, \n",
    "                                  keep_prob, \n",
    "                                  weights_file = weights_file_conv, \n",
    "                                  weights_file_last = weights_file_last_layer, \n",
    "                                  sess = sess, \n",
    "                                  finetune = True)\n",
    "\n",
    "# build cal node parameter\n",
    "predicted = tf.nn.softmax(bilinear_cnn.fc3l, name = \"predicted\")\n",
    "\n",
    "# start train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "bilinear_cnn.load_all_own_weights(sess)\n",
    "\n",
    "for v in tf.trainable_variables():\n",
    "    print(\"Trainable variables\", v)\n",
    "print('Starting predicting')\n",
    "\n",
    "\n",
    "###################################\n",
    "submit_img_batch = submit_get_batchs(tfrecord_filename = \"submit.tfrecords\", \n",
    "                                            image_size = image_size, \n",
    "                                            batch_size = submit_batch_size)\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "submit_predicted = []\n",
    "img_num = 0\n",
    "\n",
    "for i in range(int(submit_size / submit_batch_size) + 1):\n",
    "    print(1)\n",
    "    img_num = img_num + submit_batch_size\n",
    "\n",
    "    # get data\n",
    "    submit_imgs = sess.run(submit_img_batch)\n",
    "    \n",
    "    # at the end of data\n",
    "    if (img_num > submit_size):\n",
    "        submit_imgs = submit_imgs[ :-(img_num - submit_size)]\n",
    "    \n",
    "    print(2)\n",
    "    # predict single loop\n",
    "    predicted_result = sess.run(predicted, feed_dict={imgs: submit_imgs, keep_prob: 1.})\n",
    "    print(3)\n",
    "    predicted_result = list(predicted_result)\n",
    "    submit_predicted.extend(predicted_result)\n",
    "    \n",
    "    print('completed', i)\n",
    "\n",
    "# close data queue\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "\n",
    "# end\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794\n"
     ]
    }
   ],
   "source": [
    "pic_src = \"E:/PROJECT/kaggle-seedling-classification/dataset/test/\"\n",
    "all_files = os.listdir(pic_src)\n",
    "print(len(submit_predicted))\n",
    "\n",
    "class_index = ['Black-grass', 'Charlock', \n",
    "               'Cleavers', 'Common Chickweed', \n",
    "               'Common wheat', 'Fat Hen', \n",
    "               'Loose Silky-bent', 'Maize', \n",
    "               'Scentless Mayweed', 'Shepherds Purse', \n",
    "               'Small-flowered Cranesbill', 'Sugar beet']\n",
    "\n",
    "import csv  \n",
    "\n",
    "def as_num(x):\n",
    "    y = '{:.6f}'.format(x) # 6f表示保留6位小数点的float型\n",
    "    return(y)\n",
    "\n",
    "with open('output.csv', 'w+', newline='') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"file\", \"species\"])\n",
    "    for index, name in enumerate(all_files):\n",
    "        class_name = class_index[np.argmax(submit_predicted[index])]\n",
    "        writer.writerow([name, class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
